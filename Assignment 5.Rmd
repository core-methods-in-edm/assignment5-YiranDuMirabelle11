---
title: "Assignment 5 - Decision Trees"
author: "Charles Lang + Yiran Du"
date: "November 9, 2016"
output: html_document
---
For this assignment we will be using data from the Assistments Intelligent Tutoring system. This system gives students hints based on how they perform on math problems. 

#Install & call libraries
```{r}
install.packages("party", "rpart")

library(rpart)
library(party)
```

## Part I
```{r}
D1 <- read.csv("~/Desktop/github/Assignment 5/intelligent_tutor.csv")
```

##Classification Tree
First we will build a classification tree to predict which students ask a teacher for help, which start a new session, or which give up, based on whether or not the student completed a session (D1$complete) and whether or not they asked for hints (D1$hint.y). 
```{r}

c.tree <- rpart(action ~ hint.y + complete, method="class", data=D1) #Notice the standard R notion for a formula X ~ Y

#Look at the error of this tree
printcp(c.tree)

#Plot the tree
post(c.tree, file = "tree.ps", title = "Session Completion Action: 1 - Ask teacher, 2 - Start new session, 3 - Give up")

```
## Part II

#Regression Tree

We want to see if we can build a decision tree to help teachers decide which students to follow up with, based on students' performance in Assistments. We will create three groups ("teacher should intervene", "teacher should monitor student progress" and "no action") based on students' previous use of the system and how many hints they use. To do this we will be building a decision tree using the "party" package. The party package builds decision trees based on a set of statistical stopping rules.

#Take a look at our outcome variable "score"
```{r}
hist(D1$score)
```

#Create a categorical outcome variable based on student score to advise the teacher using an "ifelse" statement
```{r}
D1$advice <- ifelse(D1$score <=0.4, "intervene", ifelse(D1$score > 0.4 & D1$score <=0.8, "monitor", "no action"))
```

#Build a decision tree that predicts "advice" based on how many problems students have answered before, the percentage of those problems they got correct and how many hints they required
```{r}
score_ctree <- ctree(factor(advice) ~ prior_prob_count + prior_percent_correct + hints, D1)
```

#Plot tree
```{r}
plot(score_ctree)
```

## Please interpret the tree, which two behaviors do you think the teacher should most closely pay attemtion to?
Interpretation of the Tree: After the classification tree, students are all clustered into 5 groups. The criteria is as follows. In the first place, we divide students on the basis of their hints. If students ask for no hints, then they go to group (2), students asking for hints are grouped in group(5). 

### Node 3:
We frist look at students asking for no hints. They can be divided based on their number of problems done in the previous section. If they have finished less than 85 problems, they are grouped as Node 3 and there are 145 of them.

### Node 4: 
Students finishing more than 85 problems are labeled as Node 4 and for clarification these 76 students are who have not asked for any hints and finished more than 85 problems in the previous session.

### Node 9:
Then we look at students who asked for hints. They are divided by the cutoff of 12 hints. Those who have asked for more than 12 hints are grouped as Node 9 and there are 46 of them. 

### Node 8:
For the rest who have asked for less than 12 hints are grouped as group 6 and need further division. Group 6 are further divided based on students correctness in the previous session. Student who have asked for less than 12 hints and have a correctness more than 0.629 are finalized at Node 8 and there are 45 of them. 

### Node 7:
The rest, who have a correctness less than 0.629 end at Node 7 and there are 66 of them.

All in all, there are five groups after classification on the basis of number of hints, correctness in the prior session and problems done in the previous session.

Therefore we can know that Node 7 and Node 9 needs teachers attention to intervene. This is because when we observe the distribution of actions in each node, it can be found that the ratio of needs intervention is comparatively high in Node 7 and Node 9, reaching more than 0.2. These are the students who are either asking for more than 12 hints or student who ask for less than 12 hints but have a correctness of less than 0.629 in the previous session.

#Test Tree
Upload the data "intelligent_tutor_new.csv". This is a data set of a differnt sample of students doing the same problems in the same system. We can use the tree we built for the previous data set to try to predict the "advice" we should give the teacher about these new students. 

```{r}
#Upload new data

D2 <- read.csv("~/Desktop/github/Assignment 5/intelligent_tutor_new.csv")

#Generate predicted advice for new students based on tree generated from old students

D2$prediction <- predict(score_ctree, D2)

``` 
## Part III
Compare the predicted advice with the actual advice that these students recieved. What is the difference between the observed and predicted results?

```{r}
# The observed result
D2$advice <- ifelse(D2$score <=0.4, "intervene", ifelse(D2$score > 0.4 & D2$score <=0.8, "monitor", "no action"))

D2$overlap <- ifelse(D2$prediction==D2$advice,1,0)
sum(D2$overlap)/length(D2$overlap)

```

In dataset 2, we find that 58% of the students are predicted right in terms of actions. However, after observing the dataset, we find all the students have passed the test and the model we created is not useful for predicton for this dataset. Therefore, it is not generalizable to the second dataset.
